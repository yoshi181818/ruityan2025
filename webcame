from flask import Flask, Response, render_template_string, jsonify, send_file
from picamera2 import Picamera2
import cv2
import mediapipe as mp
import random
import time
import threading
import numpy as np
import RPi.GPIO as GPIO
import os

# ==== 設定 ====
MEASURE_DURATION = 60            # 計測時間(秒)
PREVIEW_WIDTH = 640
PREVIEW_HEIGHT = 480
BUZZER_PIN = 18                  # ブザーのGPIO(BCM)
BUZZER_ON_TIME = 1.0
FACE_IMAGE_PATH = "/tmp/face.jpg"
# ==============

app = Flask(__name__)

# グローバル状態
state_lock = threading.Lock()
state = {
    "analyzing": False,
    "start_time": None,
    "remaining_time": MEASURE_DURATION,
    "ng_counts": [0, 0, 0],        # [左, 中央, 右]
    "final_selected_person": -1,   # 0/1/2 or -1
    "reason": "",
}

# 各エリアの最新の顔画像
latest_faces = [None, None, None]

# Mediapipe
mp_face = mp.solutions.face_detection

# GPIO 初期化
GPIO.setmode(GPIO.BCM)
GPIO.setup(BUZZER_PIN, GPIO.OUT)
GPIO.output(BUZZER_PIN, GPIO.LOW)

# カメラ初期化（起動時に1回だけ）
picam2 = Picamera2()
config = picam2.create_preview_configuration(
    main={"size": (PREVIEW_WIDTH, PREVIEW_HEIGHT), "format": "BGR888"}
)
picam2.configure(config)
picam2.start()

# ======= 高級感 UI の HTML テンプレ =======
HTML = """
<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Attitude Judge System</title>
  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: radial-gradient(circle at top, #111827, #020617);
      color: #f9fafb;
      min-height: 100vh;
    }
    .container {
      max-width: 1100px;
      margin: 0 auto;
      padding: 24px 16px 40px;
    }
    /* ヘッダー */
    .header {
      text-align: center;
      margin-bottom: 24px;
    }
    .title {
      font-size: 32px;
      font-weight: 700;
      letter-spacing: 0.08em;
      text-transform: uppercase;
      background: linear-gradient(90deg, #facc15, #e5e7eb);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      margin-bottom: 6px;
    }
    .subtitle {
      font-size: 13px;
      color: #9ca3af;
    }

    /* タイマー行 */
    .top-row {
      display: flex;
      justify-content: center;
      align-items: center;
      margin: 24px 0 20px;
      gap: 16px;
      flex-wrap: wrap;
    }
    .timer-box {
      padding: 10px 22px;
      border-radius: 999px;
      border: 1px solid rgba(251,191,36,0.5);
      background: radial-gradient(circle at top, rgba(250,204,21,0.16), rgba(15,23,42,0.9));
      box-shadow: 0 0 22px rgba(250,204,21,0.35);
      display: flex;
      align-items: center;
      gap: 10px;
    }
    .timer-label {
      font-size: 13px;
      color: #e5e7eb;
      opacity: 0.8;
      text-transform: uppercase;
      letter-spacing: 0.16em;
    }
    .timer-value {
      font-size: 26px;
      font-weight: 700;
      font-variant-numeric: tabular-nums;
    }

    .start-btn {
      padding: 10px 26px;
      border-radius: 999px;
      border: 1px solid rgba(148,163,184,0.8);
      background: linear-gradient(90deg, #0f172a, #020617);
      color: #e5e7eb;
      font-size: 14px;
      font-weight: 600;
      cursor: pointer;
      display: inline-flex;
      align-items: center;
      gap: 8px;
      box-shadow: 0 5px 18px rgba(0,0,0,0.7);
      transition: transform 0.12s ease, box-shadow 0.12s ease, border 0.12s ease;
    }
    .start-btn span.icon {
      display: inline-block;
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #22c55e;
    }
    .start-btn:hover {
      transform: translateY(-1px);
      box-shadow: 0 8px 24px rgba(0,0,0,0.85);
      border-color: rgba(250,204,21,0.75);
    }
    .start-btn:active {
      transform: translateY(0px);
      box-shadow: 0 4px 12px rgba(0,0,0,0.7);
    }

    /* メインレイアウト */
    .main-grid {
      display: grid;
      grid-template-columns: minmax(0, 2.2fr) minmax(0, 1.3fr);
      gap: 20px;
    }
    @media (max-width: 900px) {
      .main-grid {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    .card {
      background: radial-gradient(circle at top left, rgba(148,163,184,0.14), rgba(15,23,42,0.96));
      border-radius: 18px;
      padding: 16px 16px 18px;
      border: 1px solid rgba(148,163,184,0.3);
      box-shadow: 0 16px 40px rgba(0,0,0,0.8);
      position: relative;
      overflow: hidden;
    }
    .card::before {
      content: "";
      position: absolute;
      inset: -40%;
      background: radial-gradient(circle at top left, rgba(250,204,21,0.12), transparent 55%);
      opacity: 0.4;
      pointer-events: none;
    }
    .card-inner {
      position: relative;
      z-index: 1;
    }

    .section-title {
      font-size: 14px;
      text-transform: uppercase;
      letter-spacing: 0.16em;
      color: #9ca3af;
      margin-bottom: 10px;
    }

    .video-frame {
      border-radius: 14px;
      overflow: hidden;
      border: 1px solid rgba(15,23,42,0.9);
      box-shadow: 0 10px 25px rgba(0,0,0,0.9);
    }
    .video-frame img {
      width: 100%;
      display: block;
    }

    /* ステータス */
    .status-bar {
      margin-top: 12px;
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 8px;
      flex-wrap: wrap;
      font-size: 13px;
      color: #e5e7eb;
    }
    .status-text {
      min-height: 18px;
    }
    .badge {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid rgba(148,163,184,0.8);
      background: rgba(15,23,42,0.9);
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 0.14em;
      color: #cbd5f5;
    }
    .dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #fbbf24;
    }

    /* 顔アップ */
    .face-wrapper {
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 14px;
    }
    .face-img-frame {
      width: 260px;
      height: 260px;
      border-radius: 50%;
      padding: 4px;
      background: radial-gradient(circle at top, rgba(250,204,21,0.5), rgba(15,23,42,0.95));
      box-shadow: 0 0 30px rgba(250,204,21,0.45);
    }
    .face-img {
      width: 100%;
      height: 100%;
      border-radius: 50%;
      object-fit: cover;
      border: 3px solid rgba(15,23,42,0.95);
    }
    .face-label {
      font-size: 13px;
      color: #e5e7eb;
      opacity: 0.85;
    }
    .winner-name {
      font-size: 16px;
      font-weight: 600;
      color: #f97373;
    }

    .ng-info {
      font-size: 12px;
      color: #9ca3af;
      margin-top: 6px;
    }

  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="title">Attitude Judge System</div>
      <div class="subtitle">3エリアの態度をAIでモニタリングし、もっとも態度が悪い人を選出します。</div>
    </header>

    <div class="top-row">
      <div class="timer-box">
        <div class="timer-label">Remaining</div>
        <div class="timer-value" id="global-timer">--:--</div>
      </div>
      <button class="start-btn" onclick="startMeasure()">
        <span class="icon"></span>
        Start Measurement
      </button>
    </div>

    <main class="main-grid">
      <!-- 左：ライブ映像 -->
      <section class="card">
        <div class="card-inner">
          <div class="section-title">Live Monitor</div>
          <div class="video-frame">
            <img id="video" src="">
          </div>
          <div class="status-bar">
            <div class="status-text" id="status">待機中…</div>
            <div class="badge">
              <div class="dot" id="badge-dot"></div>
              <span id="badge-text">Waiting</span>
            </div>
          </div>
        </div>
      </section>

      <!-- 右：結果・顔アップ -->
      <section class="card">
        <div class="card-inner">
          <div class="section-title">Result</div>
          <div class="face-wrapper">
            <div class="face-img-frame">
              <img id="face-up" class="face-img" src="/face_image?cb=0">
            </div>
            <div class="face-label">Selected Person</div>
            <div class="winner-name" id="winner-name">-</div>
            <div class="ng-info" id="ng-info">NG Count: [ -, -, - ]</div>
          </div>
        </div>
      </section>
    </main>
  </div>

  <script>
    // 映像ストリームのURLを設定（キャッシュ防止）
    window.addEventListener("load", () => {
      document.getElementById("video").src = "/video_feed?cb=" + Date.now();
    });

    async function startMeasure(){
      await fetch("/start", { method: "POST" });
    }

    function formatTime(sec){
      if (sec < 0) sec = 0;
      const m = String(Math.floor(sec / 60)).padStart(2, "0");
      const s = String(sec % 60).padStart(2, "0");
      return m + ":" + s;
    }

    function updateBadge(data){
      const dot = document.getElementById("badge-dot");
      const text = document.getElementById("badge-text");

      if (data.analyzing){
        dot.style.background = "#fbbf24"; // yellow
        text.textContent = "Analyzing";
      } else if (data.selected_person >= 0){
        dot.style.background = "#22c55e"; // green
        text.textContent = "Completed";
      } else {
        dot.style.background = "#64748b"; // gray
        text.textContent = "Waiting";
      }
    }

    async function pollStatus(){
      const res = await fetch("/status");
      const data = await res.json();

      // タイマー更新
      document.getElementById("global-timer").textContent =
        formatTime(data.remaining_time);

      // ステータステキスト
      const statusEl = document.getElementById("status");
      const names = ["左の人", "中央の人", "右の人"];

      if (data.analyzing){
        statusEl.innerHTML =
          "計測中… 残り <b>" + data.remaining_time + "</b> 秒";
      } else if (data.selected_person >= 0){
        statusEl.innerHTML =
          "選ばれたのは <b style='color:#f97373;'>" +
          names[data.selected_person] + "</b> です。<br>理由: " +
          data.reason;

        // 顔アップのリロード
        document.getElementById("face-up").src =
          "/face_image?cb=" + Date.now();
      } else {
        statusEl.textContent = "待機中…";
      }

      // Winner 名と NG情報
      const winnerNameEl = document.getElementById("winner-name");
      const ngInfoEl = document.getElementById("ng-info");
      if (data.selected_person >= 0){
        winnerNameEl.textContent = names[data.selected_person];
      } else {
        winnerNameEl.textContent = "-";
      }
      const ng = data.ng_counts;
      ngInfoEl.textContent =
        "NG Count: [ " + ng[0] + ", " + ng[1] + ", " + ng[2] + " ]";

      updateBadge(data);
    }

    setInterval(pollStatus, 1000);
  </script>
</body>
</html>
"""

# ===== Flask ルート =====

@app.route("/")
def index():
    return render_template_string(HTML)

@app.route("/start", methods=["POST"])
def start_measure():
    """計測開始（状態リセット）"""
    with state_lock:
        state["analyzing"] = True
        state["start_time"] = time.time()
        state["remaining_time"] = MEASURE_DURATION
        state["ng_counts"] = [0, 0, 0]
        state["final_selected_person"] = -1
        state["reason"] = ""
    return ("", 204)

@app.route("/status")
def status():
    with state_lock:
        return jsonify(
            analyzing=state["analyzing"],
            remaining_time=int(state["remaining_time"]),
            ng_counts=state["ng_counts"],
            selected_person=state["final_selected_person"],
            reason=state["reason"],
        )

@app.route("/face_image")
def face_image():
    """選ばれた人の顔アップ画像を返す"""
    if not os.path.exists(FACE_IMAGE_PATH):
        # まだ顔画像がない場合は黒のダミー画像を生成
        blank = np.zeros((260, 260, 3), dtype=np.uint8)
        cv2.imwrite(FACE_IMAGE_PATH, blank)
    return send_file(FACE_IMAGE_PATH, mimetype="image/jpeg")

def gen_frames():
    """映像ストリーム + 判定ロジック + 顔アップ保存"""
    global latest_faces

    face_detector = mp_face.FaceDetection(min_detection_confidence=0.5)
    area_width = PREVIEW_WIDTH // 3

    while True:
        frame = picam2.capture_array("main")  # BGR
        ih, iw, _ = frame.shape

        # AI用RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_detector.process(frame_rgb)

        faces = []
        if results.detections:
            for det in results.detections:
                bbox = det.location_data.relative_bounding_box
                x = int(bbox.xmin * iw)
                y = int(bbox.ymin * ih)
                w = int(bbox.width * iw)
                h = int(bbox.height * ih)
                cx = x + w // 2
                faces.append((cx, (x, y, w, h)))

        faces.sort(key=lambda f: f[0])
        current = [0, 0, 0]

        # 各エリアの最新顔を保存 & 枠描画
        for cx, (x, y, w, h) in faces:
            x0 = max(0, x)
            y0 = max(0, y)
            x1 = min(iw, x + w)
            y1 = min(ih, y + h)
            face_crop = frame[y0:y1, x0:x1].copy()

            if cx < area_width:
                current[0] = 1
                latest_faces[0] = face_crop
            elif cx < area_width * 2:
                current[1] = 1
                latest_faces[1] = face_crop
            else:
                current[2] = 1
                latest_faces[2] = face_crop

            cv2.rectangle(frame, (x0, y0), (x1, y1), (0, 255, 0), 2)

        # エリア区切り線
        for i in range(1, 3):
            cv2.line(frame, (area_width * i, 0),
                     (area_width * i, PREVIEW_HEIGHT), (200, 200, 200), 1)

        # ロジック（状態更新）
        with state_lock:
            if state["analyzing"] and state["start_time"] is not None:
                elapsed = time.time() - state["start_time"]
                state["remaining_time"] = max(0, MEASURE_DURATION - elapsed)

                if elapsed < MEASURE_DURATION:
                    # NGカウント更新
                    for i in range(3):
                        if current[i] == 0:
                            state["ng_counts"][i] += 1
                else:
                    # 結果決定
                    if state["final_selected_person"] == -1:
                        max_ng = max(state["ng_counts"])
                        if max_ng > 0:
                            cand = [i for i, c in enumerate(state["ng_counts"])
                                    if c == max_ng]
                            state["final_selected_person"] = random.choice(cand)
                            state["reason"] = "WORST ATTITUDE"
                        else:
                            state["final_selected_person"] = random.choice([0, 1, 2])
                            state["reason"] = "RANDOM (ALL GOOD)"

                        sel = state["final_selected_person"]

                        # 顔アップ保存
                        if 0 <= sel <= 2 and latest_faces[sel] is not None:
                            cv2.imwrite(FACE_IMAGE_PATH, latest_faces[sel])

                        # ブザー鳴動
                        GPIO.output(BUZZER_PIN, GPIO.HIGH)
                        time.sleep(BUZZER_ON_TIME)
                        GPIO.output(BUZZER_PIN, GPIO.LOW)

                    state["analyzing"] = False

        # 選ばれたエリアに赤枠
        with state_lock:
            sel_idx = state["final_selected_person"]
        if sel_idx != -1:
            sx = sel_idx * area_width
            cv2.rectangle(frame,
                          (sx + 5, 5),
                          (sx + area_width - 5, PREVIEW_HEIGHT - 5),
                          (0, 0, 255), 5)

        # ---- 表示用 GBR に変換 ----
        display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)   # RGB
        display_frame = display_frame[:, :, [1, 2, 0]]           # RGB -> GBR

        ret, buffer = cv2.imencode(".jpg", display_frame)
        if not ret:
            continue
        jpg = buffer.tobytes()

        yield (b"--frame\r\n"
               b"Content-Type: image/jpeg\r\n\r\n" + jpg + b"\r\n")

@app.route("/video_feed")
def video_feed():
    return Response(gen_frames(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")

if __name__ == "__main__":
    try:
        app.run(host="0.0.0.0", port=5000, debug=False, threaded=True)
    finally:
        picam2.stop()
        GPIO.cleanup()
